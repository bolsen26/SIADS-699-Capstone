{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install praw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "\n",
    "user_agent = \"Reddit_Scrapper 1.0 by /u/FeatureChoice5036\"\n",
    "reddit = praw.Reddit(\n",
    "    client_id=\"xxxxxxx\",\n",
    "    client_secret=\"xxxxxxxx\",\n",
    "    user_agent=user_agent\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re #RegEx : Regular expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines = set()\n",
    "for submission in reddit.subreddit(\"bitcoin\").hot(limit=None):\n",
    "    print(submission.title)#Subreddit Title\n",
    "    print(submission.id) #ID\n",
    "    print(submission.author) #Author of the subreddit\n",
    "    print(submission.created_utc) #Date and time being created\n",
    "    print(submission.score) # Average Score\n",
    "    print(submission.upvote_ratio) # Upvote ratio\n",
    "    print(submission.url) # Like to the Subreddit\n",
    "    break\n",
    "    headlines.add(submission.title)\n",
    "print(len(headlines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines = set()\n",
    "for submission in reddit.subreddit(\"bitcoin\").hot(limit=None):\n",
    "    headlines.add(submission.title)\n",
    "print(len(headlines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dataframe from the scrapped data \n",
    "bitcoin_df = pd.DataFrame(headlines)\n",
    "bitcoin_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean the text\n",
    "\n",
    "#Create a function to clean the tweets\n",
    "def cleanTxt(text):\n",
    "    text = re.sub(r'@[A-Za-z0-9]+', '', text) #Remove @mentions replace with blank\n",
    "    text = re.sub(r'#', '', text) #Remove the '#' symbol, replace with blank\n",
    "    text = re.sub(r'RT[\\s]+', '', text) #Removing RT, replace with blank\n",
    "    text = re.sub(r'https?:\\/\\/\\S+', '', text) #Remove the hyperlinks\n",
    "    text = re.sub(r':', '', text) # Remove :\n",
    "    \n",
    "    return text\n",
    "\n",
    "#Cleaning the text\n",
    "reddit_df[\"Titles\"]= reddit_df[\"Titles\"].apply(cleanTxt)\n",
    "\n",
    "#Show the clean text\n",
    "reddit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Next we have to remove emoji & Unicode from the Tweet data.\n",
    "def remove_emoji(string):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               u\"\\U0001f926-\\U0001f937\"\n",
    "                               u\"\\U00010000-\\U0010ffff\"\n",
    "                               u\"\\u2640-\\u2642\"\n",
    "                               u\"\\u2600-\\u2B55\"\n",
    "                               u\"\\u200d\"\n",
    "                               u\"\\u23cf\"\n",
    "                               u\"\\u23e9\"\n",
    "                               u\"\\u231a\"\n",
    "                               u\"\\ufe0f\"  # dingbats\n",
    "                               u\"\\u3030\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', string)\n",
    "\n",
    "#Cleaning the text\n",
    "reddit_df[\"Titles\"]= reddit_df[\"Titles\"].apply(remove_emoji)\n",
    "\n",
    "#Show the clean text\n",
    "reddit_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "from wordcloud import WordCloud, STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a function to get the subjectivity\n",
    "def getSubjectivity(text):\n",
    "    return TextBlob(text).sentiment.subjectivity\n",
    "\n",
    "#Create a function to get Polarity\n",
    "def getPolarity(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "#Now we create a new column for what we just did and add it to the Tweet_df dataframe\n",
    "reddit_df['Subjectivity'] = reddit_df['Titles'].apply(getSubjectivity)\n",
    "reddit_df['Polarity'] = reddit_df['Titles'].apply(getPolarity)\n",
    "\n",
    "#Now display data\n",
    "reddit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group the range of Polarity to different categories\n",
    "def getInsight(score):\n",
    "    if score < 0:\n",
    "        return \"Negative\"\n",
    "    elif score == 0:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Positive\"\n",
    "    \n",
    "reddit_df[\"Insight\"] = reddit_df[\"Polarity\"].apply(getInsight)\n",
    "\n",
    "reddit_df.head(50)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
